{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160742, 7)\n",
      "(306313, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_id</th>\n",
       "      <th>Merchant_id</th>\n",
       "      <th>Coupon_id</th>\n",
       "      <th>Discount_rate</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Date_received</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>8591.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160217.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1439408</td>\n",
       "      <td>2632</td>\n",
       "      <td>1078.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160319.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1832624</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160429.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2029232</td>\n",
       "      <td>3381</td>\n",
       "      <td>11951.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2223968</td>\n",
       "      <td>3381</td>\n",
       "      <td>9776.0</td>\n",
       "      <td>10:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160129.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>73611</td>\n",
       "      <td>2099</td>\n",
       "      <td>12034.0</td>\n",
       "      <td>100:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>163606</td>\n",
       "      <td>1569</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>200:30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160421.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3273056</td>\n",
       "      <td>4833</td>\n",
       "      <td>7802.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160130.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94107</td>\n",
       "      <td>3381</td>\n",
       "      <td>7610.0</td>\n",
       "      <td>200:20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160412.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>253750</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160327.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>376492</td>\n",
       "      <td>1041</td>\n",
       "      <td>13490.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160127.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964720</td>\n",
       "      <td>7884</td>\n",
       "      <td>6704.0</td>\n",
       "      <td>20:1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20160215.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1113008</td>\n",
       "      <td>1041</td>\n",
       "      <td>11197.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20160114.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2881376</td>\n",
       "      <td>8390</td>\n",
       "      <td>7531.0</td>\n",
       "      <td>20:5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20160321.0</td>\n",
       "      <td>20160329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2881376</td>\n",
       "      <td>5341</td>\n",
       "      <td>111.0</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20160207.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_id  Merchant_id  Coupon_id Discount_rate  Distance  Date_received  \\\n",
       "0   1439408         2632        NaN           NaN       0.0            NaN   \n",
       "1   1439408         2632     8591.0          20:1       0.0     20160217.0   \n",
       "2   1439408         2632     1078.0          20:1       0.0     20160319.0   \n",
       "3   1832624         3381     7610.0        200:20       0.0     20160429.0   \n",
       "4   2029232         3381    11951.0        200:20       1.0     20160129.0   \n",
       "5   2223968         3381     9776.0          10:5       2.0     20160129.0   \n",
       "6     73611         2099    12034.0        100:10       NaN     20160207.0   \n",
       "7    163606         1569     5054.0        200:30      10.0     20160421.0   \n",
       "8   3273056         4833     7802.0        200:20      10.0     20160130.0   \n",
       "9     94107         3381     7610.0        200:20       2.0     20160412.0   \n",
       "10   253750         8390        NaN           NaN       0.0            NaN   \n",
       "11   253750         8390     7531.0          20:5       0.0     20160327.0   \n",
       "12   376492         1041    13490.0          30:5       2.0     20160127.0   \n",
       "13  1964720         7884        NaN           NaN      10.0            NaN   \n",
       "14  1964720         7884     6704.0          20:1      10.0     20160215.0   \n",
       "15  1113008         1041        NaN           NaN       2.0            NaN   \n",
       "16  1113008         1041    11197.0          30:5       2.0     20160114.0   \n",
       "17  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "18  2881376         8390     7531.0          20:5       0.0     20160321.0   \n",
       "19  2881376         5341      111.0          30:5       1.0     20160207.0   \n",
       "\n",
       "          Date  \n",
       "0   20160217.0  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  \n",
       "10  20160327.0  \n",
       "11         NaN  \n",
       "12         NaN  \n",
       "13  20160115.0  \n",
       "14         NaN  \n",
       "15  20160114.0  \n",
       "16         NaN  \n",
       "17         NaN  \n",
       "18  20160329.0  \n",
       "19         NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfoff = pd.read_csv(os.path.join('mid_exam/train_offline.csv'))\n",
    "dftest = pd.read_csv(os.path.join('mid_exam/test_offline.csv'))\n",
    "dftest = dftest[~dftest.Coupon_id.isna()]\n",
    "dftest.reset_index(drop=True, inplace=True)\n",
    "print(dfoff.shape)\n",
    "print(dftest.shape)\n",
    "dfoff.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dfoff.dropna(subset=['Date_received'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(746969, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "df['Discount_rate']=df['Discount_rate'].fillna('1:0')\n",
    "new=df['Discount_rate'].str.split(':',n=1,expand=True)\n",
    "df['rate0']=new[0].astype(float)\n",
    "df['rate1']=new[1].astype(float)\n",
    "df['Distance']=df['Distance'].fillna(df['Distance'].median())\n",
    "def label(row):\n",
    "    if np.isnan(row['Date_received']):\n",
    "        return -1\n",
    "    if not np.isnan(row['Date']):\n",
    "        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n",
    "        if td <= pd.Timedelta(15, 'D'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "df[\"label\"] = df.apply(label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['rate']=1-df['rate1']/df['rate0']\n",
    "df['dateofweek']=df.apply(lambda row: pd.to_datetime(row.Date_received, format = \"%Y%m%d\").dayofweek, axis=1)\n",
    "df=df.drop(columns=['Discount_rate','Date'])\n",
    "# weekday_type (weekend = 1)\n",
    "df['weekday_type'] = df['dateofweek'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 642491, #positive: 29886\n",
      "Valid size: 77019, #positive: 3515\n"
     ]
    }
   ],
   "source": [
    "## Naive model\n",
    "def split_train_valid(row, date_cut=\"20160416\"):\n",
    "    is_train = True if pd.to_datetime(row, format=\"%Y%m%d\") < pd.to_datetime(date_cut, format=\"%Y%m%d\") else False\n",
    "    return is_train\n",
    "    \n",
    "df[\"is_train\"] = df[\"Date_received\"].apply(split_train_valid)\n",
    "train = df[df[\"is_train\"]]\n",
    "valid = df[~df[\"is_train\"]]\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "valid.reset_index(drop=True, inplace=True)\n",
    "print(\"Train size: {}, #positive: {}\".format(len(train), train[\"label\"].sum()))\n",
    "print(\"Valid size: {}, #positive: {}\".format(len(valid), valid[\"label\"].sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 ['Distance', 'Date_received', 'rate0', 'rate1', 'rate', 'dateofweek', 'weekday_type']\n"
     ]
    }
   ],
   "source": [
    "original_feature = ['Distance','Date_received','rate0','rate1','rate','dateofweek','weekday_type']\n",
    "print(len(original_feature),original_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold, cross_val_score,cross_validate, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score, auc, roc_curve\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Distance', 'Date_received', 'rate0', 'rate1', 'rate', 'dateofweek', 'weekday_type']\n"
     ]
    }
   ],
   "source": [
    "predictors = original_feature\n",
    "print(predictors)\n",
    "\n",
    "def check_model(data, predictors):\n",
    "    \n",
    "    classifier = lambda: SGDClassifier(\n",
    "        loss='log', \n",
    "        penalty='elasticnet', \n",
    "        fit_intercept=True, \n",
    "        max_iter=100, \n",
    "        shuffle=True, \n",
    "        n_jobs=1,\n",
    "        class_weight=None)\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('ss', StandardScaler()),\n",
    "        ('en', classifier())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'en__alpha': [ 0.001, 0.01, 0.1],\n",
    "        'en__l1_ratio': [ 0.001, 0.01, 0.1]\n",
    "    }\n",
    "\n",
    "    folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        model, \n",
    "        parameters, \n",
    "        cv=folder, \n",
    "        n_jobs=-1, \n",
    "        verbose=1)\n",
    "    grid_search = grid_search.fit(data[predictors], \n",
    "                                  data['label'])\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:  2.9min finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:467: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = check_model(train, predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = model.predict_proba(valid[predictors])\n",
    "valid1 = valid.copy()\n",
    "valid1['pred_prob'] = y_valid_pred[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC: 0.764, Accuracy: 0.954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "auc_score = roc_auc_score(y_true=valid.label, y_score=y_valid_pred[:,1])\n",
    "acc = accuracy_score(y_true=valid.label, y_pred=y_valid_pred.argmax(axis=1))\n",
    "print(\"Validation AUC: {:.3f}, Accuracy: {:.3f}\".format(auc_score, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['Discount_rate'].fillna('1:1')\n",
    "newtest=dftest['Discount_rate'].str.split(':',n=1,expand=True)\n",
    "dftest['rate0']=newtest[0].astype(float)\n",
    "dftest['rate1']=newtest[1].astype(float)\n",
    "dftest['Distance']=dftest['Distance'].fillna(dftest['Distance'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['rate']=1-dftest['rate1']/dftest['rate0']\n",
    "dftest['dateofweek']=dftest.apply(lambda row: pd.to_datetime(row.Date_received, format = \"%Y%m%d\").dayofweek, axis=1)\n",
    "dftest=dftest.drop(columns=['Discount_rate'])\n",
    "# weekday_type (weekend = 1)\n",
    "dftest['weekday_type'] = dftest['dateofweek'].astype('str').apply(lambda x : 1 if x in [6,7] else 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest['rate1']=dftest['rate1'].fillna(0)\n",
    "dftest['rate']=dftest['rate'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 10)\n",
      "(306313, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:381: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "targetset = dftest.copy()\n",
    "print(targetset.shape)\n",
    "targetset = targetset[~targetset.Coupon_id.isna()]\n",
    "targetset.reset_index(drop=True, inplace=True)\n",
    "testset = targetset[predictors].copy()\n",
    "\n",
    "y_test_pred = model.predict_proba(testset[predictors])\n",
    "test1 = testset.copy()\n",
    "test1['pred_prob'] = y_test_pred[:, 1]\n",
    "print(test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306313, 4)\n"
     ]
    }
   ],
   "source": [
    "output = pd.concat((targetset[[\"User_id\", \"Coupon_id\", \"Date_received\"]], test1[\"pred_prob\"]), axis=1)\n",
    "print(output.shape)\n",
    "\n",
    "output.loc[:, \"User_id\"] = output[\"User_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Coupon_id\"] = output[\"Coupon_id\"].apply(lambda x:str(int(x)))\n",
    "output.loc[:, \"Date_received\"] = output[\"Date_received\"].apply(lambda x:str(int(x)))\n",
    "output[\"uid\"] = output[[\"User_id\", \"Coupon_id\", \"Date_received\"]].apply(lambda x: '_'.join(x.values), axis=1)\n",
    "output.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000020_2705_20160519</td>\n",
       "      <td>0.298537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000020_8192_20160513</td>\n",
       "      <td>0.287693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000065_1455_20160527</td>\n",
       "      <td>0.216241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000085_8067_20160513</td>\n",
       "      <td>0.237481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000086_2418_20160613</td>\n",
       "      <td>0.326696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     uid     label\n",
       "0  1000020_2705_20160519  0.298537\n",
       "1  1000020_8192_20160513  0.287693\n",
       "2  1000065_1455_20160527  0.216241\n",
       "3  1000085_8067_20160513  0.237481\n",
       "4  1000086_2418_20160613  0.326696"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### NOTE: YOUR SUBMITION FILE SHOULD HAVE COLUMN NAME: uid, label\n",
    "out = output.groupby(\"uid\", as_index=False).mean()\n",
    "out = out[[\"uid\", \"pred_prob\"]]\n",
    "out.columns = [\"uid\", \"label\"]\n",
    "out.to_csv(\"midexam.csv\", header=[\"uid\", \"label\"], index=False) # submission format\n",
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
